<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- The title will be updated dynamically from /title.txt -->
    <title>Loading…</title>
    <style>
      /* Global Dark Mode & Mobile Friendly */
      :root {
        --bg-color: #121212;
        --text-color: #e0e0e0;
        --accent-color: #1e88e5;
        --accent-hover: #1565c0;
        --border-color: #333;
      }
      body {
        background-color: var(--bg-color);
        color: var(--text-color);
        margin: 0;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
      }
      #app {
        max-width: 500px;
        margin: 0 auto;
        padding: 20px;
      }
      h1 {
        text-align: center;
        font-size: 1.8em;
      }
      /* Player Styles */
      #player {
        border: 1px solid var(--border-color);
        padding: 15px;
        border-radius: 8px;
        background-color: #1e1e1e;
        margin-bottom: 20px;
      }
      #timeDisplay {
        text-align: center;
        margin-bottom: 10px;
        font-size: 1.1em;
      }
      input[type="range"] {
        width: 100%;
        margin: 10px 0;
      }
      #controls {
        display: flex;
        justify-content: center;
      }
      #controls button {
        background-color: var(--accent-color);
        color: #fff;
        border: none;
        padding: 10px 15px;
        margin: 0 5px;
        border-radius: 4px;
        font-size: 1em;
        cursor: pointer;
      }
      #controls button:hover {
        background-color: var(--accent-hover);
      }
      /* Content Text */
      #content p {
        line-height: 1.6;
        margin-bottom: 15px;
      }
    </style>
  </head>
  <body>
    <div id="app">
      <!-- Page title will be updated from /title.txt -->
      <h1 id="pageTitle">Loading…</h1>

      <!-- Music Player -->
      <div id="player">
        <div id="timeDisplay">
          <span id="currentTime">00:00</span> /
          <span id="totalTime">00:00</span>
        </div>
        <input id="scrubber" type="range" min="0" max="0" step="0.01" value="0" />
        <div id="controls">
          <button id="backButton">-10s</button>
          <button id="playPauseButton">Play</button>
          <button id="forwardButton">+10s</button>
        </div>
      </div>

      <!-- Hidden audio element used as the main audio source -->
      <audio id="mainAudio" loop style="display: none;"></audio>

      <!-- Content fetched from /text.txt will be appended here -->
      <div id="content"></div>
    </div>

    <script>
      // Global variables
      let audioCtx;
      let binauralPlaying = false;
      let binauralNodes = {};
      const fadeDuration = 2; // seconds for binaural fade-in

      // Utility: Format seconds into mm:ss
      function formatTime(sec) {
        if (isNaN(sec)) return "00:00";
        const minutes = Math.floor(sec / 60);
        const seconds = Math.floor(sec % 60);
        return (
          (minutes < 10 ? "0" + minutes : minutes) +
          ":" +
          (seconds < 10 ? "0" + seconds : seconds)
        );
      }

      // Convert an AudioBuffer to a WAV formatted ArrayBuffer.
      // This implementation creates a 16-bit PCM WAV.
      function audioBufferToWav(buffer, opt) {
        opt = opt || {};
        const numChannels = buffer.numberOfChannels;
        const sampleRate = buffer.sampleRate;
        const format = opt.float32 ? 3 : 1;
        const bitDepth = format === 3 ? 32 : 16;
      
        let result;
        const numSamples = buffer.length * numChannels;
        const blockAlign = numChannels * (bitDepth / 8);
        const byteRate = sampleRate * blockAlign;
        const dataSize = buffer.length * blockAlign;
        const bufferSize = 44 + dataSize;
        const arrayBuffer = new ArrayBuffer(bufferSize);
        const view = new DataView(arrayBuffer);
      
        // Helper to write strings to the DataView
        function writeString(view, offset, string) {
          for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
          }
        }
      
        let offset = 0;
        // RIFF identifier
        writeString(view, offset, "RIFF");
        offset += 4;
        // RIFF chunk length
        view.setUint32(offset, 36 + dataSize, true);
        offset += 4;
        // RIFF type
        writeString(view, offset, "WAVE");
        offset += 4;
        // Format chunk identifier
        writeString(view, offset, "fmt ");
        offset += 4;
        // Format chunk length
        view.setUint32(offset, 16, true);
        offset += 4;
        // Sample format (raw)
        view.setUint16(offset, format, true);
        offset += 2;
        // Number of channels
        view.setUint16(offset, numChannels, true);
        offset += 2;
        // Sample rate
        view.setUint32(offset, sampleRate, true);
        offset += 4;
        // Byte rate (sample rate * block align)
        view.setUint32(offset, byteRate, true);
        offset += 4;
        // Block align (channel count * bytes per sample)
        view.setUint16(offset, blockAlign, true);
        offset += 2;
        // Bits per sample
        view.setUint16(offset, bitDepth, true);
        offset += 2;
        // Data chunk identifier
        writeString(view, offset, "data");
        offset += 4;
        // Data chunk length
        view.setUint32(offset, dataSize, true);
        offset += 4;
      
        // Write interleaved PCM samples
        const channelData = [];
        for (let i = 0; i < numChannels; i++) {
          channelData.push(buffer.getChannelData(i));
        }
      
        for (let i = 0; i < buffer.length; i++) {
          for (let channel = 0; channel < numChannels; channel++) {
            let sample = channelData[channel][i];
            // Clamp the sample
            sample = Math.max(-1, Math.min(1, sample));
            if (format === 1) {
              // 16-bit PCM
              const intSample =
                sample < 0 ? sample * 0x8000 : sample * 0x7fff;
              view.setInt16(offset, intSample, true);
              offset += 2;
            } else {
              view.setFloat32(offset, sample, true);
              offset += 4;
            }
          }
        }
        return arrayBuffer;
      }

      // Initialize AudioContext (will be resumed on user interaction)
      function initAudioContext() {
        if (!audioCtx) {
          audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        }
      }

      // Binaural Beats: Start two oscillators with slightly different frequencies.
      function startBinauralBeats() {
        // Prevent multiple instances
        if (binauralPlaying) return;
        initAudioContext();
        const now = audioCtx.currentTime;
      
        // Left oscillator: 100 Hz
        const leftOsc = audioCtx.createOscillator();
        leftOsc.frequency.value = 100;
        const leftGain = audioCtx.createGain();
        leftGain.gain.setValueAtTime(0, now);
        leftGain.gain.linearRampToValueAtTime(0.004, now + fadeDuration);
        const leftPanner = audioCtx.createStereoPanner();
        leftPanner.pan.value = -1; // full left
      
        // Right oscillator: 102 Hz
        const rightOsc = audioCtx.createOscillator();
        rightOsc.frequency.value = 102;
        const rightGain = audioCtx.createGain();
        rightGain.gain.setValueAtTime(0, now);
        rightGain.gain.linearRampToValueAtTime(0.004, now + fadeDuration);
        const rightPanner = audioCtx.createStereoPanner();
        rightPanner.pan.value = 1; // full right
      
        // Connect nodes: oscillator -> gain -> panner -> destination
        leftOsc.connect(leftGain);
        leftGain.connect(leftPanner);
        leftPanner.connect(audioCtx.destination);
      
        rightOsc.connect(rightGain);
        rightGain.connect(rightPanner);
        rightPanner.connect(audioCtx.destination);
      
        // Start oscillators immediately
        leftOsc.start();
        rightOsc.start();
      
        binauralNodes = {
          leftOsc,
          rightOsc,
          leftGain,
          rightGain,
          leftPanner,
          rightPanner,
        };
        binauralPlaying = true;
      }

      // Stop the binaural beats
      function stopBinauralBeats() {
        if (!binauralPlaying) return;
        try {
          binauralNodes.leftOsc.stop();
          binauralNodes.rightOsc.stop();
        } catch (err) {
          console.error(err);
        }
        binauralNodes = {};
        binauralPlaying = false;
      }

      // Update the timer display and scrubber
      function updateTime() {
        const audio = document.getElementById("mainAudio");
        const currentTimeElem = document.getElementById("currentTime");
        const totalTimeElem = document.getElementById("totalTime");
        const scrubber = document.getElementById("scrubber");
        currentTimeElem.textContent = formatTime(audio.currentTime);
        if (!isNaN(audio.duration) && audio.duration > 0) {
          totalTimeElem.textContent = formatTime(audio.duration);
          scrubber.max = audio.duration;
          scrubber.value = audio.currentTime;
        }
      }

      // Main initialization function
      async function init() {
        initAudioContext();
        const mainAudio = document.getElementById("mainAudio");
        const playPauseBtn = document.getElementById("playPauseButton");
        const backBtn = document.getElementById("backButton");
        const forwardBtn = document.getElementById("forwardButton");
        const scrubber = document.getElementById("scrubber");

        // Fetch and set page title from /title.txt
        try {
          const resTitle = await fetch("/title.txt");
          const titleText = await resTitle.text();
          document.title = titleText;
          document.getElementById("pageTitle").textContent = titleText;
        } catch (err) {
          console.error("Error fetching title.txt:", err);
        }
      
        // Fetch and display content from /text.txt
        try {
          const resText = await fetch("/text.txt");
          const textData = await resText.text();
          // Split into paragraphs by double newline
          const paragraphs = textData.split(/\n{2,}/);
          const contentDiv = document.getElementById("content");
          paragraphs.forEach((p) => {
            const paraElem = document.createElement("p");
            paraElem.textContent = p.trim();
            if (paraElem.textContent) {
              contentDiv.appendChild(paraElem);
            }
          });
        } catch (err) {
          console.error("Error fetching text.txt:", err);
        }
      
        // Fetch the main audio (/audio.mp3), append 10 seconds of silence,
        // convert to a WAV Blob, and set it as the source for the audio element.
        try {
          const resAudio = await fetch("/audio.mp3");
          const audioData = await resAudio.arrayBuffer();
          const decodedBuffer = await audioCtx.decodeAudioData(audioData);
          // Create new AudioBuffer with extra 10 seconds of silence
          const extraSamples = audioCtx.sampleRate * 10;
          const newLength = decodedBuffer.length + extraSamples;
          const newBuffer = audioCtx.createBuffer(
            decodedBuffer.numberOfChannels,
            newLength,
            decodedBuffer.sampleRate
          );
          for (let channel = 0; channel < decodedBuffer.numberOfChannels; channel++) {
            const oldData = decodedBuffer.getChannelData(channel);
            const newData = newBuffer.getChannelData(channel);
            newData.set(oldData);
            // The rest of newData is already zero (silence)
          }
          // Convert the new AudioBuffer to WAV and create a blob URL
          const wavArrayBuffer = audioBufferToWav(newBuffer);
          const wavBlob = new Blob([wavArrayBuffer], { type: "audio/wav" });
          const objectUrl = URL.createObjectURL(wavBlob);
          mainAudio.src = objectUrl;
          mainAudio.load();
        } catch (err) {
          console.error("Error processing audio.mp3:", err);
        }
      
        // Event Listeners for Audio Element
      
        // Update time & scrubber during playback
        mainAudio.addEventListener("timeupdate", updateTime);
      
        // Update scrubber max on metadata loaded
        mainAudio.addEventListener("loadedmetadata", updateTime);
      
        // Play/pause toggle button
        playPauseBtn.addEventListener("click", async () => {
          // Resume AudioContext if in suspended state (required by some browsers)
          if (audioCtx.state === "suspended") {
            await audioCtx.resume();
          }
          if (mainAudio.paused) {
            mainAudio.play();
            playPauseBtn.textContent = "Pause";
          } else {
            mainAudio.pause();
            playPauseBtn.textContent = "Play";
          }
        });
      
        // Backward 10s button
        backBtn.addEventListener("click", () => {
          mainAudio.currentTime = Math.max(mainAudio.currentTime - 10, 0);
        });
      
        // Forward 10s button
        forwardBtn.addEventListener("click", () => {
          mainAudio.currentTime = Math.min(
            mainAudio.currentTime + 10,
            mainAudio.duration || mainAudio.currentTime + 10
          );
        });
      
        // Scrubber (range slider) controls playback position
        scrubber.addEventListener("input", () => {
          mainAudio.currentTime = scrubber.value;
        });
      
        // Start binaural beats when audio plays and stop when paused
        mainAudio.addEventListener("play", () => {
          startBinauralBeats();
        });
      
        mainAudio.addEventListener("pause", () => {
          stopBinauralBeats();
        });
      }
      
      // Initialize when DOM is ready
      document.addEventListener("DOMContentLoaded", init);
    </script>
  </body>
</html>
