<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Listen</title>
    <style>
      /* Global Styles & Dark Mode */
      * {
        box-sizing: border-box;
      }
      body {
        margin: 0;
        padding: 0;
        background-color: #121212;
        color: #e0e0e0;
        font-family: Arial, sans-serif;
        line-height: 1.6;
        display: flex;
        flex-direction: column;
        min-height: 100vh;
      }
      /* Main Content */
      #content {
        flex: 1;
        padding: 20px;
        padding-bottom: 20vh; /* extra space so content isn’t hidden behind player */
      }
      h1 {
        margin-top: 0;
        font-size: 2rem;
        text-align: center;
      }
      #text-content p {
        margin-bottom: 1em;
      }
      /* Audio Player - fixed at bottom */
      #audio-player {
        position: fixed;
        bottom: 0;
        left: 0;
        right: 0;
        height: 15vh;
        background-color: #1e1e1e;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        padding: 10px 20px;
      }
      #controls {
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 15px;
        width: 100%;
      }
      #controls button {
        background-color: #333;
        border: none;
        color: #e0e0e0;
        font-size: 1.4rem;
        padding: 8px 12px;
        border-radius: 4px;
        cursor: pointer;
      }
      #controls button:hover {
        background-color: #444;
      }
      #controls span {
        font-size: 1rem;
      }
      /* Scrubber style */
      #scrubber {
        width: 90%;
        margin-top: 8px;
      }
      /* Mobile responsiveness */
      @media (max-width: 600px) {
        h1 {
          font-size: 1.6rem;
        }
        #controls button {
          font-size: 1.2rem;
          padding: 6px 10px;
        }
      }
    </style>
  </head>
  <body>
    <div id="content">
      <!-- Default title; will be updated from /title.txt -->
      <h1 id="page-title">Listen</h1>
      <!-- Paragraphs loaded from /text.txt -->
      <div id="text-content"></div>
    </div>

    <!-- Audio Player Section -->
    <div id="audio-player">
      <div id="controls">
        <button id="back" title="Back 10 seconds">⏪</button>
        <button id="play-pause" title="Play / Pause">▶️</button>
        <button id="forward" title="Forward 10 seconds">⏩</button>
        <span id="current-time">0:00</span> / <span id="duration">0:00</span>
      </div>
      <input type="range" id="scrubber" min="0" max="100" step="0.1" value="0" />
    </div>

    <!-- Hidden audio element; its source will be set with a blob URL -->
    <audio id="main-audio" preload="auto" loop style="display: none;"></audio>

    <script>
      // Global variables
      let audioContext; // for processing the main audio file
      let beatAudioContext; // separate context for binaural beats
      let binauralBeatsNodes = null; // store binaural beat nodes

      // Helper: Format seconds as mm:ss
      function formatTime(seconds) {
        const m = Math.floor(seconds / 60);
        const s = Math.floor(seconds % 60);
        return m + ":" + (s < 10 ? "0" : "") + s;
      }

      // Fetch and update page title from /title.txt
      fetch("/title.txt", { cache: "reload" })
        .then((res) => res.text())
        .then((txt) => {
          document.getElementById("page-title").innerText = txt.trim();
          document.title = txt.trim();
        })
        .catch((err) => console.error("Title fetch error:", err));

      // Fetch and display text paragraphs from /text.txt
      fetch("/text.txt", { cache: "reload" })
        .then((res) => res.text())
        .then((txt) => {
          const container = document.getElementById("text-content");
          // Split by double newlines to get paragraphs
          txt.split("\n\n").forEach((para) => {
            if (para.trim() !== "") {
              const pElem = document.createElement("p");
              pElem.innerText = para.trim();
              container.appendChild(pElem);
            }
          });
        })
        .catch((err) => console.error("Text fetch error:", err));

      // Append silence to an AudioBuffer
      function appendSilence(buffer, silenceSeconds) {
        const channels = buffer.numberOfChannels;
        const sampleRate = buffer.sampleRate;
        const silenceLength = Math.floor(silenceSeconds * sampleRate);
        const newLength = buffer.length + silenceLength;
        const newBuffer = audioContext.createBuffer(channels, newLength, sampleRate);

        for (let channel = 0; channel < channels; channel++) {
          const channelData = newBuffer.getChannelData(channel);
          channelData.set(buffer.getChannelData(channel)); // copy original data; rest remains 0 (silence)
        }
        return newBuffer;
      }

      // Helper: Write a string to a DataView at a given offset
      function writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      }

      // Encode an AudioBuffer into a WAV ArrayBuffer
      function encodeWAV(buffer) {
        const numChannels = buffer.numberOfChannels;
        const sampleRate = buffer.sampleRate;
        const bitsPerSample = 16;
        const numSamples = buffer.length;
        const blockAlign = numChannels * (bitsPerSample / 8);
        const byteRate = sampleRate * blockAlign;
        const dataSize = numSamples * blockAlign;
        const bufferLength = 44 + dataSize;
        const arrayBuffer = new ArrayBuffer(bufferLength);
        const view = new DataView(arrayBuffer);

        // RIFF header
        writeString(view, 0, "RIFF");
        view.setUint32(4, 36 + dataSize, true);
        writeString(view, 8, "WAVE");
        // fmt chunk
        writeString(view, 12, "fmt ");
        view.setUint32(16, 16, true); // chunk size
        view.setUint16(20, 1, true); // format PCM
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, byteRate, true);
        view.setUint16(32, blockAlign, true);
        view.setUint16(34, bitsPerSample, true);
        // data chunk
        writeString(view, 36, "data");
        view.setUint32(40, dataSize, true);

        // Write PCM samples
        let offset = 44;
        for (let i = 0; i < numSamples; i++) {
          for (let channel = 0; channel < numChannels; channel++) {
            let sample = buffer.getChannelData(channel)[i];
            // Clamp the sample
            sample = Math.max(-1, Math.min(1, sample));
            // Scale to 16-bit PCM
            const intSample = sample < 0 ? sample * 0x8000 : sample * 0x7fff;
            view.setInt16(offset, intSample, true);
            offset += 2;
          }
        }
        return arrayBuffer;
      }

      // Setup main audio: fetch, process (append 10s silent pause), encode and assign blob URL
      async function setupAudio() {
        // Create an AudioContext for decoding and processing
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        try {
          const response = await fetch("/audio.mp3", { cache: "reload" });
          const arrayBuffer = await response.arrayBuffer();
          audioContext.decodeAudioData(
            arrayBuffer,
            (decodedBuffer) => {
              // Append 10 seconds of silence after the audio data
              const newBuffer = appendSilence(decodedBuffer, 10);
              // Encode the new buffer as a WAV file so we can use it as our audio source
              const wavArrayBuffer = encodeWAV(newBuffer);
              const blob = new Blob([wavArrayBuffer], { type: "audio/wav" });
              const blobUrl = URL.createObjectURL(blob);
              const mainAudio = document.getElementById("main-audio");
              mainAudio.src = blobUrl;
              mainAudio.load();
            },
            (error) => {
              console.error("Error decoding audio data:", error);
            }
          );
        } catch (err) {
          console.error("Audio fetch error:", err);
        }

        // Setup audio player controls
        const mainAudio = document.getElementById("main-audio");
        const playPauseBtn = document.getElementById("play-pause");
        const backBtn = document.getElementById("back");
        const forwardBtn = document.getElementById("forward");
        const scrubber = document.getElementById("scrubber");
        const currentTimeDisplay = document.getElementById("current-time");
        const durationDisplay = document.getElementById("duration");

        mainAudio.addEventListener("loadedmetadata", () => {
          scrubber.max = mainAudio.duration;
          durationDisplay.innerText = formatTime(mainAudio.duration);
        });

        mainAudio.addEventListener("timeupdate", () => {
          currentTimeDisplay.innerText = formatTime(mainAudio.currentTime);
          scrubber.value = mainAudio.currentTime;
        });

        scrubber.addEventListener("input", () => {
          mainAudio.currentTime = scrubber.value;
        });

        playPauseBtn.addEventListener("click", () => {
          if (mainAudio.paused) {
            mainAudio.play();
          } else {
            mainAudio.pause();
          }
        });

        backBtn.addEventListener("click", () => {
          mainAudio.currentTime = Math.max(mainAudio.currentTime - 10, 0);
        });

        forwardBtn.addEventListener("click", () => {
          mainAudio.currentTime = Math.min(mainAudio.currentTime + 10, mainAudio.duration);
        });

        // Update play/pause button icon and handle binaural beats
        mainAudio.addEventListener("play", () => {
          playPauseBtn.innerText = "⏸️";
          startBinauralBeats();
        });
        mainAudio.addEventListener("pause", () => {
          playPauseBtn.innerText = "▶️";
          stopBinauralBeats();
        });
      }

      // Binaural Beats: start two oscillators (left 100 Hz, right 130 Hz) with low gain & fade in
      function startBinauralBeats() {
        if (binauralBeatsNodes) return; // already running
        beatAudioContext = new (window.AudioContext || window.webkitAudioContext)();

        const oscLeft = beatAudioContext.createOscillator();
        oscLeft.frequency.value = 100;
        const oscRight = beatAudioContext.createOscillator();
        oscRight.frequency.value = 130;

        const gainLeft = beatAudioContext.createGain();
        const gainRight = beatAudioContext.createGain();
        // Start with zero gain for fade in
        gainLeft.gain.value = 0;
        gainRight.gain.value = 0;

        const pannerLeft = beatAudioContext.createStereoPanner();
        pannerLeft.pan.value = -1;
        const pannerRight = beatAudioContext.createStereoPanner();
        pannerRight.pan.value = 1;

        // Connect the audio graph for each oscillator
        oscLeft.connect(gainLeft).connect(pannerLeft).connect(beatAudioContext.destination);
        oscRight.connect(gainRight).connect(pannerRight).connect(beatAudioContext.destination);

        oscLeft.start();
        oscRight.start();

        // Fade in the gain to 0.004 over 2 seconds
        const now = beatAudioContext.currentTime;
        gainLeft.gain.linearRampToValueAtTime(0.004, now + 2);
        gainRight.gain.linearRampToValueAtTime(0.004, now + 2);

        binauralBeatsNodes = { oscLeft, oscRight, gainLeft, gainRight, beatAudioContext };
      }

      function stopBinauralBeats() {
        if (binauralBeatsNodes) {
          binauralBeatsNodes.oscLeft.stop();
          binauralBeatsNodes.oscRight.stop();
          binauralBeatsNodes.beatAudioContext.close();
          binauralBeatsNodes = null;
        }
      }

      // Initialize after page load
      window.addEventListener("load", setupAudio);
    </script>
  </body>
</html>
